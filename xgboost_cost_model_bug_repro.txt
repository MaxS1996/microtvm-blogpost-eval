Traceback (most recent call last):

  File "micro_eval/end_to_end/tune_relay_microtvm.py", line 320, in <module>
    tune_and_eval_model()

  File "micro_eval/end_to_end/tune_relay_microtvm.py", line 298, in tune_and_eval_model
    tune_model(tasks)

  File "micro_eval/end_to_end/tune_relay_microtvm.py", line 238, in tune_model
    autotvm.callback.log_to_file(tmp_log_file)])

  File "/home/lweber/tvm-micro/python/tvm/autotvm/tuner/xgboost_tuner.py", line 86, in tune
    super(XGBTuner, self).tune(*args, **kwargs)

  File "/home/lweber/tvm-micro/python/tvm/autotvm/tuner/tuner.py", line 156, in tune
    self.update(inputs, results)

  File "/home/lweber/tvm-micro/python/tvm/autotvm/tuner/model_based_tuner.py", line 266, in update
    self.cost_model.fit(self.xs, self.ys, self.plan_size)

  File "/home/lweber/tvm-micro/python/tvm/autotvm/tuner/xgboost_cost_model.py", line 181, in fit
    x_train = self._get_feature(xs)

  File "/home/lweber/tvm-micro/python/tvm/autotvm/tuner/xgboost_cost_model.py", line 324, in _get_feature
    ret[i, :] = t if t is not None else 0

ValueError: could not broadcast input array from shape (284) into shape (302)

----------------------------------------------------------------------------------------------------

////////////////////////
// FEATURE COUNT: 282 //
////////////////////////

////////////
// CONFIG //
////////////
[
    ('tile_ow', [-1, 4]),
    ('tile_ci', [-1, 32]),
    ('tile_co', [-1, 16]),
    ('reorder_0_simd', [0, 1, 6, 7, 2, 4, 8, 3, 5, 9]),
    ('auto_unroll_max_step', 4),
    ('unroll_explicit', 1)
],
direct,
None,
3937

//////////
// IMPL //
//////////

// attr [padded_data] storage_scope = "global"
allocate padded_data[int8 * 12800]
produce padded_data {
  for (i1, 0, 20) {
    for (i2, 0, 20) {
      for (i3, 0, 32) {
        padded_data[(((i1*640) + (i2*32)) + i3)] = tvm_if_then_else(((((2 <= i1) && (i1 < 18)) && (2 <= i2)) && (i2 < 18)), data[((((i1*512) + (i2*32)) + i3) - 1088)], (int8)0)
      }
    }
  }
}
produce conv2d {
  for (yy, 0, 16) {
    for (xx.outer.init, 0, 4) {
      gemm_4x32x16_reset(tvm_access_ptr(type_annotation(), conv2d, ((yy*512) + (xx.outer.init*128)), 128, 2), 32)
      gemm_4x32x16_reset(tvm_access_ptr(type_annotation(), conv2d, (((yy*512) + (xx.outer.init*128)) + 16), 128, 2), 32)
    }
    for (ry, 0, 5) {
      for (rx, 0, 5) {
        for (xx.outer, 0, 4) {
          gemm_4x32x16_update(tvm_access_ptr(type_annotation(), padded_data, ((((yy*640) + (ry*640)) + (xx.outer*128)) + (rx*32)), 128, 1), tvm_access_ptr(type_annotation(), kernel, ((ry*5120) + (rx*1024)), 512, 1), tvm_access_ptr(type_annotation(), conv2d, ((yy*512) + (xx.outer*128)), 128, 2), 32, 32, 32)
          gemm_4x32x16_update(tvm_access_ptr(type_annotation(), padded_data, ((((yy*640) + (ry*640)) + (xx.outer*128)) + (rx*32)), 128, 1), tvm_access_ptr(type_annotation(), kernel, (((ry*5120) + (rx*1024)) + 512), 512, 1), tvm_access_ptr(type_annotation(), conv2d, (((yy*512) + (xx.outer*128)) + 16), 128, 2), 32, 32, 32)
        }
      }
    }
  }
}

----------------------------------------------------------------------------------------------------

////////////////////////
// FEATURE COUNT: 300 //
////////////////////////

////////////
// CONFIG //
////////////
[
    ('tile_ow', [-1, 8]),
    ('tile_ci', [-1, 16]),
    ('tile_co', [-1, 16]),
    ('reorder_0_simd', [0, 6, 7, 1, 2, 4, 8, 3, 5, 9]),
    ('auto_unroll_max_step', 32),
    ('unroll_explicit', 0)
],
direct,
None,
2733

//////////
// IMPL //
//////////

// attr [padded_data] storage_scope = "global"
allocate padded_data[int8 * 12800]
produce padded_data {
  for (i1, 0, 20) {
    for (i2, 0, 20) {
      for (i3, 0, 32) {
        padded_data[(((i1*640) + (i2*32)) + i3)] = tvm_if_then_else(((((2 <= i1) && (i1 < 18)) && (2 <= i2)) && (i2 < 18)), data[((((i1*512) + (i2*32)) + i3) - 1088)], (int8)0)
      }
    }
  }
}
produce conv2d {
  for (yy.init, 0, 16) {
    unrolled (xx.outer.init, 0, 2) {
      unrolled (ff.outer.init, 0, 2) {
        gemm_8x16x16_reset(tvm_access_ptr(type_annotation(), conv2d, (((yy.init*512) + (xx.outer.init*256)) + (ff.outer.init*16)), 256, 2), 32)
      }
    }
  }
  for (ry, 0, 5) {
    for (rx, 0, 5) {
      for (yy, 0, 16) {
        unrolled (xx.outer, 0, 2) {
          unrolled (ff.outer, 0, 2) {
            unrolled (rc.outer, 0, 2) {
              gemm_8x16x16_update(tvm_access_ptr(type_annotation(), padded_data, (((((yy*640) + (ry*640)) + (xx.outer*256)) + (rx*32)) + (rc.outer*16)), 256, 1), tvm_access_ptr(type_annotation(), kernel, ((((ry*5120) + (rx*1024)) + (ff.outer*512)) + (rc.outer*16)), 512, 1), tvm_access_ptr(type_annotation(), conv2d, (((yy*512) + (xx.outer*256)) + (ff.outer*16)), 256, 2), 32, 32, 32)
            }
          }
        }
      }
    }
  }
}
